import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Dense
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE

MODEL_PATH = "saved_models/custom_model.h5"

def train_model(target_column="Target_A"):
    df = pd.read_csv("uploaded_data/data.csv")

    # ì…ë ¥ ë°ì´í„°(X)ì™€ ì •ë‹µ ë°ì´í„°(Y) ë¶„ë¦¬
    X = df.drop(columns=["ID", "Target_A", "Target_B"])
    y = df[target_column]

    # ë°ì´í„° ì •ê·œí™”
    scaler = StandardScaler()
    X = scaler.fit_transform(X)

    # ë°ì´í„° ë¶„í¬ í™•ì¸
    unique, counts = np.unique(y, return_counts=True)
    print(f"ğŸ“Š ì •ë‹µ(Label) ë¶„í¬: {dict(zip(unique, counts))}")

    # ë°ì´í„° ë¶ˆê· í˜• í•´ê²° (SMOTE ì ìš©)
    smote = SMOTE(sampling_strategy='auto', random_state=42)
    X_resampled, y_resampled = smote.fit_resample(X, y)

    # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í• 
    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)

    # ëª¨ë¸ ì •ì˜
    model = Sequential([
        Dense(64, activation='relu', input_shape=(X_train.shape[1],)),
        Dense(32, activation='relu'),
        Dense(1, activation='sigmoid')
    ])

    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    model.fit(X_train, y_train, epochs=50, batch_size=16, verbose=1)

    # í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê°€
    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)
    print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_accuracy:.4f}")

    model.save(MODEL_PATH)
    return MODEL_PATH


def predict(features):
    model = load_model(MODEL_PATH)
    features = np.array(features).reshape(1, -1)
    prediction = model.predict(features)
    return float(prediction[0][0])
